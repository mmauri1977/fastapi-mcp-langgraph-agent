# FastAPI LangGraph Agent with Next.js UI

A production-ready FastAPI template for building AI agent applications with LangGraph integration and a modern Next.js UI. This template provides a robust foundation for building scalable, secure, and maintainable AI agent services.

## ðŸŒŸ Features

### Backend (API)

- **Production-Ready Architecture**
  - FastAPI for high-performance async API endpoints
  - LangGraph integration for AI agent workflows
  - Langfuse for LLM observability and monitoring
  - Structured logging with environment-specific formatting
  - Rate limiting with configurable rules
  - PostgreSQL for data persistence
  - Docker and Docker Compose support
  - Prometheus metrics and Grafana dashboards for monitoring

- **Security**
  - JWT-based authentication
  - Session management
  - Input sanitization
  - CORS configuration
  - Rate limiting protection

- **Developer Experience**
  - Environment-specific configuration
  - Comprehensive logging system
  - Clear project structure
  - Type hints throughout
  - Easy local development setup

- **Model Evaluation Framework**
  - Automated metric-based evaluation of model outputs
  - Integration with Langfuse for trace analysis
  - Detailed JSON reports with success/failure metrics
  - Interactive command-line interface
  - Customizable evaluation metrics

### Frontend (UI)

- Modern Next.js application
- Real-time chat interface
- Authentication system
- Responsive design
- Integration with LangGraph API

## ðŸš€ Quick Start

### Prerequisites

- Python 3.13+ (for API)
- Node.js and npm/yarn/pnpm/bun (for UI)
- PostgreSQL
- Docker and Docker Compose (optional)

## Running with Docker Compose

The easiest way to get started is using Docker Compose, which will set up all required services:

1. Clone the repository:
```bash
git clone <repository-url>
cd <project-directory>
```

2. Copy the example environment files:
```bash
cp api/.env.example api/.env.development
cp ui/.env.example ui/.env.local
```

3. Update the environment files with your configuration:
- In `api/.env.development`:
  ```
  POSTGRES_URL="postgresql://postgres:postgres@postgres:5432/bot"
  LANGFUSE_HOST="http://langfuse-web:3000"
  # Add other required variables
  ```
- In `ui/.env.local`:
  ```
  LANGGRAPH_API_URL=http://localhost:8000
  NEXT_PUBLIC_LANGGRAPH_ASSISTANT_ID=your_assistant_id
  ```

4. Start the Docker environment:
```bash
docker compose up -d
```

This will start:
- FastAPI backend on http://localhost:8000
- Next.js frontend on http://localhost:3000
- PostgreSQL database
- Prometheus metrics on http://localhost:9090
- Grafana dashboards on http://localhost:3005 (default credentials: admin/admin)
- Langfuse observability platform
- Supporting services (Redis, MinIO, ClickHouse)

## Running Components Standalone

### Running the API Standalone

1. Navigate to the API directory:
```bash
cd api
```

2. Create and activate a virtual environment:
```bash
uv sync
```

3. Set up your environment:
```bash
cp .env.example .env.development
# Update .env.development with your configuration
```

4. Start the API:
```bash
make dev
```

The API will be available at http://localhost:8000

### Running the UI Standalone

1. Navigate to the UI directory:
```bash
cd ui
```

2. Install dependencies:
```bash
npm install
# or yarn install
# or pnpm install
# or bun install
```

3. Set up your environment:
```bash
cp .env.example .env.local
# Update .env.local with your configuration
```

4. Start the development server:
```bash
npm run dev
# or yarn dev
# or pnpm dev
# or bun dev
```

The UI will be available at http://localhost:3000

## ðŸ“Š Model Evaluation

The project includes a robust evaluation framework for measuring and tracking model performance over time. The evaluator automatically fetches traces from Langfuse, applies evaluation metrics, and generates detailed reports.

### Running Evaluations

You can run evaluations with different options using the provided Makefile commands:

```bash
# Interactive mode with step-by-step prompts
make eval [ENV=development|staging|production]

# Quick mode with default settings (no prompts)
make eval-quick [ENV=development|staging|production]

# Evaluation without report generation
make eval-no-report [ENV=development|staging|production]
```

### Evaluation Features

- Interactive CLI with colored output and progress bars
- Flexible configuration with runtime customization
- Detailed JSON reports with comprehensive metrics
- Customizable evaluation metrics

## ðŸ”§ Configuration

The application uses a flexible configuration system with environment-specific settings:

- `.env.development` - Development environment settings
- `.env.staging` - Staging environment settings
- `.env.production` - Production environment settings

## ðŸ“š Documentation

- API Swagger documentation: http://localhost:8000/docs
- API ReDoc documentation: http://localhost:8000/redoc
- Grafana dashboards: http://localhost:3005
- Prometheus metrics: http://localhost:9090
- Langfuse observability: http://localhost:3003
